{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, interactive\n",
    "from sklearn.preprocessing import PolynomialFeatures, Normalizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn.apionly as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def true_function(x):\n",
    "    return x**3 - x**2 - 5*x \n",
    "def create_data(n_samples, noise):\n",
    "    x = np.linspace(-4, 4, n_samples)\n",
    "    f = true_function(x)\n",
    "    y = true_function(x) + noise*np.random.randn(n_samples)\n",
    "    data = np.zeros((n_samples,3))\n",
    "    data[:, 0] = x\n",
    "    data[:, 1] = y\n",
    "    data[:, 2] = f\n",
    "    norm = StandardScaler()\n",
    "    return norm.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "data = create_data(30,10)\n",
    "X_train = data[:,0][:, np.newaxis]\n",
    "y_train = data[:,1]\n",
    "f = data[:,2]\n",
    "\n",
    "data_test = create_data(20,10)\n",
    "X_test = data_test[:,0][:, np.newaxis]\n",
    "y_test = data_test[:,1]\n",
    "\n",
    "plt.plot(X_train,f, 'k-',alpha=0.6, label='true function')\n",
    "plt.scatter(X_train,y_train, label='training samples',color='C0',s=50)\n",
    "plt.scatter(X_test,y_test, label='test samples',color='C1', s=50)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend(frameon=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creazione del modello di predizione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati provengono da un modello non lineare, un metodo semplice per creare un modello in grado di fare predizioni non lineari è quello di utilizzare features polinomiali.\n",
    "\n",
    "Ma quale è il grado delle features polinomiali che meglio approssima la funzione vera?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(train_set, degrees):\n",
    "    train_dict = {}\n",
    "    for d in degrees:\n",
    "        train_dict[d] = PolynomialFeatures(d).fit_transform(train_set)\n",
    "    return train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees=range(21)\n",
    "train_dict = make_features(X_train, degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_train=np.empty(len(degrees))\n",
    "for d in degrees:\n",
    "    X_train_poly = train_dict[d]   \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    y_hat = model.predict(X_train_poly)\n",
    "    error_train[d] = mean_squared_error(y_train, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestd = np.argmin(error_train)\n",
    "plt.plot(degrees, error_train, marker='o', label='train')\n",
    "plt.plot(bestd, error_train[bestd], marker='*',markersize=25, color='r', label=\"min train error at d=%d\"%bestd, alpha=0.8)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('degree')\n",
    "plt.legend(loc=0,frameon=True)\n",
    "#plt.yscale(\"log\")\n",
    "plt.xticks(range(21));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Che indicazioni ci da questo grafico?\n",
    "- che il modello migliore in termini di errore quandratico medio sul nostro training set è il modello di grado 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predizione sui dati di test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro obiettivo è quello di testare il modello allenato sui dati di train, e il cui ordine è stato scelto dall'analisi precedente, sul dataset di test. \n",
    "\n",
    "Dal momento che il modello performa bene sul set di train su cui è stato allenato, è ragionevole aspettarsi che questo modello performi bene anche sul set di test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 20\n",
    "pipeline = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,100)[:, np.newaxis]\n",
    "plt.plot(x, pipeline.predict(x), linestyle='--',label='learned model',color='C0')\n",
    "plt.scatter(X_train, y_train, label='train samples',color='C0',s=50)\n",
    "plt.scatter(X_test, y_test, label='test samples',color='C1',s=50)\n",
    "plt.plot(X_train, f, 'k-',alpha=0.6, label='true function')\n",
    "plt.ylim(-4,3)\n",
    "plt.xlim(np.min(X_train),np.max(X_train))\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.text(-0.5, -2.3, \"training score: $MSE$ = {0:.2f}\".format(mean_squared_error(y_train,pipeline.predict(X_train))),\n",
    "         color='C0')\n",
    "plt.text(-0.5, -2.8, \"test score: $MSE$ = {0:.2f}\".format(mean_squared_error(y_test,pipeline.predict(X_test))), color='C1')\n",
    "plt.legend(frameon=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error1 = mean_squared_error(y_test,pipeline.predict(X_test))\n",
    "test_error1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'errore di test è 3 ordini di grandezza superiore rispetto all'errore di train, come mai si discostano così tanto?\n",
    "\n",
    "Cerchiamo di capire, tramite un'analisi grafica di sensitività, come variano errore di train ed errore di test al variare dell'ordine del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=(1,30)\n",
    "def plot_poly(degree=1):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree,\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    x = np.linspace(-1.7,1.7,100)[:, np.newaxis]\n",
    "    plt.plot(x, pipeline.predict(x), linestyle='--', label=\"learned model\")\n",
    "    plt.plot(X_train, f, 'k-',alpha=0.6,label=\"true function\")\n",
    "    plt.scatter(X_train, y_train, label=\"train samples\",color='C0',s=50)\n",
    "    plt.scatter(X_test, y_test, label=\"test samples\",color='C1',s=50)\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$y$\")\n",
    "    plt.ylim((-4, 3))\n",
    "    plt.xlim(np.min(X_train),np.max(X_train))\n",
    "    plt.legend(loc=\"upper center\",frameon=True)\n",
    "    plt.text(-0.5, -2.3, \"training score: $MSE$ = {0:.2f}\".format(mean_squared_error(y_train,pipeline.predict(X_train))),\n",
    "         color='C0')\n",
    "    plt.text(-0.5, -2.8, \"test score: $MSE$ = {0:.2f}\".format(mean_squared_error(y_test,pipeline.predict(X_test))), color='C1')\n",
    "    plt.show()\n",
    "    \n",
    "w=interactive(plot_poly, degree=r)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osservazioni dal grafico interattivo:\n",
    "\n",
    "- i modelli di ordine basso (ordini 1 e 2) non siano in grado di approssimare in maniera sufficientemente accurata la forma del modello vero da cui sono stati generati i dati, si osserva che l'errore di train e l'errore di test sono simili come valori ed entrambi relativamente alti. Si dice che questi modelli soffrano di **bias elevato** o anche di **underfitting**;\n",
    "\n",
    "- il modello di ordine 3 è in grado di approssimare in maniera accurata la funzione vera, ciò è ragionevole dal momento che il modello vero è appunto una funzione di grado 3. In questa situazione i valori degli errori di train e di test sono simili ed entrambi bassi;\n",
    "\n",
    "- mano a mano che l'ordine si alza, si osserva che i modelli allenati hanno delle forme sempre più complesse. Questi modelli, oltre ad imparare la forma della funzione vera, tendono ad imparare anche il rumore contenuto nello specifico training set su cui sono allenati. Si osserva che errore di train ed errore di test appaiono molto differenti, in particolare l'errore di train tende a decrescere con l'aumentare dell'ordine del modello (addirittura quando il grado del modello è lo stesso del numero dei dati di train questi ultimi vengono interpolati e si ottiene perciò errore nullo). Al contrario l'errore di test tende ad aumentare in maniera molto elevata all'aumentare dell'ordine del modello. Si dice che questi modelli soffrano di **varianza elevata** o anche di **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo degli errori di test di un modello che soffre di bias elevato e di un modello che soffre di varianza elevata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=20,include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_error2 = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "test_error2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=1,include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_error3 = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "test_error3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Valutazione di un modello tramite le curve di apprendimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un metodo utile per valutare le performances di un modello in termini di bias/varianza è quello di plottare le curve di apprendimento, esse illustrano il processo di apprendimento al variare del numero dei campioni del training set.\n",
    "Quando un dataset è piccolo, è facile che un modello complesso lo fitti con precisione rischiando però di fare overfitting. Mano a mano che il dataset cresce è ragionevole aspettarsi che l'errore di train aumenti. Al contrario, con un dataset piccolo è facile che il modello allenato su di esso non generalizzi bene su dati nuovi e di conseguenza l'errore di test sarà elevato. Mano a mano che il dataset cresce ci si aspetta che il modello generalizzi meglio e che quindi l'errore di test diminuisca.\n",
    "Ci forniscono, inoltre, indicazioni empiriche molto utili sul numero di dati di train che dovremmo utilizzare per allenare il modello fissato un ordine tenendo sotto controllo underfitting e overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    np.random.seed(0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_train_predict = model.predict(X_train[:m])\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
    "        val_errors.append(mean_squared_error(y_val_predict, y_val))\n",
    "    plt.plot((train_errors), \"C0\", linewidth=3, label=\"train\")\n",
    "    plt.plot((val_errors), \"C1\", linewidth=3, label=\"test\")\n",
    "    plt.ylim(0,2)\n",
    "    plt.xlabel('training set size')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.legend(frameon=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_degree = (1,30)\n",
    "np.random.seed(0)\n",
    "def learning_curves(degree=1):\n",
    "    data = create_data(200,5)\n",
    "    X_train = data[:,0][:, np.newaxis]\n",
    "    y_train = data[:,1]\n",
    "    polynomial_features = PolynomialFeatures(degree=degree,include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                             (\"linear_regression\", linear_regression)])\n",
    "    plot_learning_curves(pipeline, X_train, y_train)\n",
    "\n",
    "w=interactive(learning_curves,degree=r_degree)\n",
    "w    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una tecnica utilissima per combattere ovefitting e underfitting è quella utilizzare parte dei dati di train per la validazione del modello, questi dati fanno parte di un nuovo dataset che vieno chiamato **dataset di validazione**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "data = create_data(30,10)\n",
    "X_train = data[:,0][:, np.newaxis]\n",
    "y_train = data[:,1]\n",
    "f = data[:,2]\n",
    "\n",
    "data_test = create_data(20,10)\n",
    "X_test = data_test[:,0][:, np.newaxis]\n",
    "y_test = data_test[:,1]\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "plt.plot(X_train,f, 'k-',alpha=0.6, label='true function')\n",
    "plt.scatter(X_train,y_train, label='training samples',color='C0',s=50)\n",
    "plt.scatter(X_test,y_test, label='validation samples',color='C1', s=50)\n",
    "plt.scatter(X_val,y_val, label='validation samples',color='C2',s=100,marker='s',alpha=0.5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend(frameon=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(train_set, test_set, degrees):\n",
    "    train_dict = {}\n",
    "    test_dict = {}\n",
    "    for d in degrees:\n",
    "        traintestdict={}\n",
    "        train_dict[d] = PolynomialFeatures(d).fit_transform(train_set.reshape(-1,1))\n",
    "        test_dict[d] = PolynomialFeatures(d).fit_transform(test_set.reshape(-1,1))\n",
    "    return train_dict, test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees=range(21)\n",
    "train_dict, val_dict = make_features(X_train2, X_val, degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_train=np.empty(len(degrees))\n",
    "error_val=np.empty(len(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in degrees:\n",
    "    X_train_poly = train_dict[d]\n",
    "    X_val_poly = val_dict[d]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train2)\n",
    "    y_train_hat = model.predict(X_train_poly)\n",
    "    y_val_hat = model.predict(X_val_poly)\n",
    "    error_train[d] = mean_squared_error(y_train2, y_train_hat)\n",
    "    error_val[d] = mean_squared_error(y_val, y_val_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestd = np.argmin(error_val)\n",
    "print('Best model degree: ' + str(bestd))\n",
    "plt.plot(degrees, error_train, marker='o', label='train')\n",
    "plt.plot(degrees, error_val, marker='o', label='validation',c='C2')\n",
    "plt.plot(bestd, error_val[bestd], marker='*',markersize=25, color='r', label=\"min val error at d=%d\"%bestd, alpha=0.8)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('degree')\n",
    "plt.legend(loc='upper left',frameon=True)\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(range(21));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predizione con il modello migliore trovato in fase di validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refitting sull'intero training set e e calcolo dell'errore di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=bestd,include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_error4 = mean_squared_error(y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['High variance model','High bias model','Validated model']\n",
    "sns.stripplot(errors,[test_error2, test_error3, test_error4],s=30)\n",
    "plt.ylabel('Mean Squared Error');\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['High bias model','Validated model']\n",
    "sns.stripplot(errors,[test_error3, test_error4],s=30)\n",
    "plt.ylabel('Mean Squared Error');\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La cross-validazione è una tecnica utilizzabile in presenza di una buona numerosità del campione osservato o training set. In particolare la k-fold cross-validation consiste nella suddivisione del dataset totale in k parti di uguale numerosità e, ad ogni passo, la k-esima parte del dataset viene ad essere il validation dataset, mentre la restante parte costituisce il training dataset. Così, per ognuna delle k parti (di solito k = 10) si allena il modello, evitando quindi problemi di overfitting, ma anche di campionamento asimmetrico (e quindi affetto da bias) del training dataset, tipico della suddivisione del dataset in due sole parti (ovvero training e validation dataset). In altre parole, si suddivide il campione osservato in gruppi di egual numerosità, si esclude iterativamente un gruppo alla volta e lo si cerca di predire con i gruppi non esclusi. Ciò al fine di verificare la bontà del modello di predizione utilizzato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "data = create_data(30,10)\n",
    "X_train = data[:,0][:, np.newaxis]\n",
    "y_train = data[:,1]\n",
    "f = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "degrees=range(21)\n",
    "train_errors = np.zeros((21,n_folds))\n",
    "valid_errors = np.zeros((21,n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "for train, valid in KFold(n_folds, shuffle=True).split(range(30)): \n",
    "    train_dict, valid_dict = make_features(X_train[train], X_train[valid], degrees)\n",
    "    for d in degrees:\n",
    "        est = LinearRegression()\n",
    "        est.fit(train_dict[d], y_train[train]) # fit\n",
    "        train_errors[d, fold] = mean_squared_error(y_train[train], est.predict(train_dict[d])) \n",
    "        valid_errors[d, fold] = mean_squared_error(y_train[valid], est.predict(valid_dict[d])) \n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_train_errors = train_errors.mean(axis=1)\n",
    "mean_valid_errors = valid_errors.mean(axis=1)\n",
    "std_train_errors = train_errors.std(axis=1)\n",
    "std_valid_errors = valid_errors.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "mindeg = np.argmin(mean_valid_errors)\n",
    "print('Best model degree: ' + str(mindeg))\n",
    "post_cv_train_dict, test_dict=make_features(X_train, X_test, degrees)\n",
    "est = LinearRegression()\n",
    "est.fit(post_cv_train_dict[mindeg], y_train) \n",
    "pred = est.predict(test_dict[mindeg])\n",
    "err = mean_squared_error(pred, y_test)\n",
    "errtr=mean_squared_error(y_train, est.predict(post_cv_train_dict[mindeg]))\n",
    "#plt.errorbar(degrees, [r[0] for r in results], yerr=[r[3] for r in results], marker='o', label='CV error', alpha=0.5)\n",
    "plt.plot(degrees, mean_train_errors, marker='o', label='CV error train', alpha=0.9)\n",
    "plt.plot(degrees, mean_valid_errors, marker='o', label='CV error val', alpha=0.9,c='C2')\n",
    "\n",
    "\n",
    "plt.fill_between(degrees, mean_valid_errors-std_valid_errors, mean_valid_errors+std_valid_errors, color='C2', alpha=0.2)\n",
    "plt.fill_between(degrees, mean_train_errors-std_train_errors, mean_train_errors+std_train_errors, color='C0', alpha=0.2)\n",
    "\n",
    "\n",
    "plt.plot([mindeg], [err], 'o',  label='test set error',color='red')#,markersize=25)\n",
    "plt.xticks(np.arange(21))\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('degree')\n",
    "plt.legend(loc=0,frameon=True)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error5=err\n",
    "errors = ['High variance model','High bias model','Validated model','Cross-validated model']\n",
    "sns.stripplot(errors,[test_error2, test_error3, test_error4, test_error5],s=30)\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['High bias model','Validated model','Cross-validated model']\n",
    "sns.stripplot(errors,[test_error3, test_error4, test_error5],s=30)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiaramente le performances dei modelli ottenuti in fase di validazione e in fase di cross-validazione sono identiche dal momento che il grado ottimale individuato in entrambi i casi era lo stesso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regolarizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = create_data(30,10)\n",
    "X_train = data[:,0][:, np.newaxis]\n",
    "y_train = data[:,1]\n",
    "f = data[:,2]\n",
    "\n",
    "data_test = create_data(20,10)\n",
    "X_test = data_test[:,0][:, np.newaxis]\n",
    "y_test = data_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_alpha = (-10,2)\n",
    "def regularization(alpha=-10):\n",
    "    alpha=10**alpha\n",
    "    degrees=range(21)\n",
    "    fig, col = plt.subplots(1, 2)\n",
    "    d=19\n",
    "    train_dict, test_dict = make_features(X_train, X_test, degrees)\n",
    "    X_train_poly = train_dict[d]\n",
    "    X_test_poly = test_dict[d]\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_poly, y_train)\n",
    "    col[0].plot(X_train, f, 'k-',alpha=0.6, label='true function')\n",
    "    col[0].plot(X_train, y_train, '.', label=\"training\")\n",
    "    col[0].plot(X_test, y_test, '.', label=\"testing\",color='C1')\n",
    "    x=np.arange(-1.6,1.6,0.01)\n",
    "    X = PolynomialFeatures(d).fit_transform(x.reshape(-1,1))\n",
    "    col[0].plot(x, ridge.predict(X),  '--', label=\"$\\lambda$ = %s\" % str(alpha),color='C0')\n",
    "    #ax.set_ylim((0, 1))\n",
    "    #ax.set_xlim((0, 1))\n",
    "    col[0].text(-1.7, 2.3, \"training score: $mse$ = {0:.2f}\".format(mean_squared_error(y_train,ridge.predict(X_train_poly))),\n",
    "         color='C0')\n",
    "    col[0].text(-1.7, 2.6, \"test score: $mse$ = {0:.2f}\".format(mean_squared_error(y_test,ridge.predict(X_test_poly))), \n",
    "                color='C1')\n",
    "    col[0].set_ylabel('y')\n",
    "    col[0].set_xlabel('x')\n",
    "    col[0].legend(loc='lower right')\n",
    "    col[0].set_ylim(-3,3)\n",
    "    coef = ridge.coef_.ravel()\n",
    "    col[1].semilogy(np.abs(coef), marker='o', label=\"$\\lambda$ = %s\" % str(alpha))\n",
    "    col[1].set_ylim((0, 1e4))\n",
    "    col[1].set_ylabel('abs(coefficient)')\n",
    "    col[1].set_xlabel('coefficients')\n",
    "    col[1].legend(loc='upper left')\n",
    "    col[1].set_xticks=(np.arange(20))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "w=interactive(regularization, alpha=r_alpha)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scelta del parametro $\\lambda$ tramite cross-validazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = create_data(100,10) \n",
    "X_train = data[:,0][:, np.newaxis]\n",
    "y_train = data[:,1]\n",
    "f = data[:,2]\n",
    "\n",
    "data_test = create_data(20,10)\n",
    "X_test = data_test[:,0][:, np.newaxis]\n",
    "y_test = data_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "degree = 30\n",
    "pipeline = Pipeline([('polynomial_features',PolynomialFeatures(degree)),('ridge', Ridge())])\n",
    "param_grid = [{'ridge__alpha': np.logspace(-8,2,100)}]\n",
    "grid = GridSearchCV(pipeline, cv=2, n_jobs=-1, param_grid=param_grid,scoring=\"mean_squared_error\")\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refitting sull'intero dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_best = grid.best_params_['ridge__alpha']\n",
    "est = Ridge(alpha=lambda_best).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = lambda_best\n",
    "degrees = range(21)\n",
    "fig, col = plt.subplots(1, 2)\n",
    "d=19\n",
    "train_dict, test_dict = make_features(X_train, X_test, degrees)\n",
    "X_train_poly = train_dict[d]\n",
    "X_test_poly = test_dict[d]\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train_poly, y_train)\n",
    "col[0].plot(X_train, f, 'k-',alpha=0.6, label='true function')\n",
    "col[0].plot(X_train, y_train, '.', label=\"training\")\n",
    "col[0].plot(X_test, y_test, '.', label=\"testing\",color='C1')\n",
    "x=np.arange(-1.6,1.6,0.01)\n",
    "X = PolynomialFeatures(d).fit_transform(x.reshape(-1,1))\n",
    "col[0].plot(x, ridge.predict(X),'--', label=\"$\\lambda$ = %s\" % str(alpha),color='C0')\n",
    "#ax.set_ylim((0, 1))\n",
    "#ax.set_xlim((0, 1))\n",
    "col[0].text(-1.7, 2.3, \"training score: $mse$ = {0:.2f}\".format(mean_squared_error(y_train,ridge.predict(X_train_poly))),\n",
    "     color='C0')\n",
    "col[0].text(-1.7, 2.6, \"test score: $mse$ = {0:.2f}\".format(mean_squared_error(y_test,ridge.predict(X_test_poly))), \n",
    "            color='C1')\n",
    "col[0].set_ylabel('y')\n",
    "col[0].set_xlabel('x')\n",
    "col[0].legend(loc='lower right')\n",
    "col[0].set_ylim(-3,3)\n",
    "coef = ridge.coef_.ravel()\n",
    "col[1].semilogy(np.abs(coef), marker='o', label=\"$\\lambda$ = %s\" % str(alpha))\n",
    "col[1].set_ylim((0, 1e4))\n",
    "col[1].set_ylabel('abs(coefficient)')\n",
    "col[1].set_xlabel('coefficients')\n",
    "col[1].legend(loc='upper left')\n",
    "col[1].set_xticks=(np.arange(20))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errore di test prima e dopo la regolarizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=30,include_bias=False)\n",
    "regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"linear_regression\", regression)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_error6 = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "test_error6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=30,include_bias=False)\n",
    "ridge = Ridge(alpha=lambda_best)\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"ridge_regression\", ridge)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "test_error7 = mean_squared_error(y_test, pipeline.predict(X_test))\n",
    "test_error7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
